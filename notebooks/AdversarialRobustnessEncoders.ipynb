{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "AdversarialRobustnessEncoders.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmi6t37teMk6"
   },
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MTRTwzibs-GP"
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LeakyReLU,Conv2D, BatchNormalization, Flatten, InputLayer, concatenate, ReLU\n",
    "from tensorflow.keras.layers import Conv2DTranspose,Input,Dense,Reshape, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from encoders import *\n",
    "from noises import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100, cifar10"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "(train_data_clean, _), (test_data_clean, _) = cifar100.load_data()\n",
    "train_data_clean = train_data_clean.astype('float32')/255.\n",
    "train_data_noisy = np.zeros(train_data_clean.shape)\n",
    "for i in range(train_data_clean.shape[0]):\n",
    "    train_data_noisy[i] =  normal_noise(train_data_clean[i])\n",
    "test_data_noisy = np.zeros(test_data_clean.shape)\n",
    "for i in range(test_data_clean.shape[0]):\n",
    "    test_data_noisy[i] =  normal_noise(test_data_clean[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTJAjvzPe_Vo"
   },
   "source": [
    "### Simple U- Net autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wzxPv5hNe-xR"
   },
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import os\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "modelU = UNetModel(32,256)\n",
    "modelU.compile(loss= 'mean_squared_error', optimizer=tf.keras.optimizers.Adam(clipnorm=1), metrics=['accuracy'])\n",
    "#encoded = modelU.encode(train_data_clean[:10])"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmCB63Pbfl9o",
    "outputId": "25490981-a0a7-4844-a561-28550e0f85c3"
   },
   "source": [
    "Unet_history = modelU.fit(train_data_noisy,train_data_clean, batch_size=64,verbose=1, epochs=40, validation_split=0.15, callbacks=[ callback])\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " No MLCTrainingGraph has been found.\n\t [[node gradient_tape/mean_squared_error/MLCMeanSquaredErrorGrad (defined at /Users/smaket/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5883) ]]\n\t [[MLCSubgraphOp_0_6]] [Op:__inference_train_function_4863]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mean_squared_error/MLCMeanSquaredErrorGrad:\n u_net_model/StatefulPartitionedCall (defined at <ipython-input-4-2236102244f1>:1)\t\n mean_squared_error/MLCMeanSquaredError (defined at /Users/smaket/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5801)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-2236102244f1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mUnet_history\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodelU\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data_noisy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtrain_data_clean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m40\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.15\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1098\u001B[0m                 _r=1):\n\u001B[1;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    886\u001B[0m         \u001B[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m         \u001B[0;31m# stateless function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 888\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    889\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m       \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[1;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2942\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   2944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1916\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1917\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1918\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1919\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    553\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 555\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    556\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInternalError\u001B[0m:  No MLCTrainingGraph has been found.\n\t [[node gradient_tape/mean_squared_error/MLCMeanSquaredErrorGrad (defined at /Users/smaket/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5883) ]]\n\t [[MLCSubgraphOp_0_6]] [Op:__inference_train_function_4863]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mean_squared_error/MLCMeanSquaredErrorGrad:\n u_net_model/StatefulPartitionedCall (defined at <ipython-input-4-2236102244f1>:1)\t\n mean_squared_error/MLCMeanSquaredError (defined at /Users/smaket/miniforge3/envs/tf24/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5801)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6COZRVrEWOV8",
    "outputId": "4cb6ce2a-4615-4260-b0b2-08b6f8594464"
   },
   "source": [
    "plt.plot(Unet_history.history['loss'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXChthxxZ446",
    "outputId": "ba01b974-d432-40ee-fe52-da2886b931bf"
   },
   "source": [
    "modelUNoDense = UNetModel(32,256, True)\n",
    "modelUNoDense.compile(loss= 'mean_squared_error', optimizer=tf.keras.optimizers.Adam(clipnorm=1), metrics=['accuracy'])\n",
    "\n",
    "UneNoDenset_history = modelUNoDense.fit(train_data_noisy,train_data_clean, batch_size=64,verbose=1, epochs=40, validation_split=0.15, callbacks=[ callback])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMIGeqOAfDxo"
   },
   "source": [
    "### U - net autoencoder with dense layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIbIQKkXfKqS"
   },
   "source": [
    "### Cusomized Simple Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97yHAXPkfPT0",
    "outputId": "1c5f4ab3-e016-4883-b324-6b881bfa96c1"
   },
   "source": [
    "\n",
    "model = SimpleDAE(256*2*2)\n",
    "model.compile(loss = 'mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Simple_DEA_history = model.fit(train_data_noisy,train_data_clean, batch_size=64,verbose=1, epochs=40, validation_split=0.15,callbacks=[callback])\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "1mOR7VEigj4w",
    "outputId": "4675006f-7f72-4397-bed8-3a01f279047d"
   },
   "source": [
    "predU = modelU.predict(train_data_noisy[:10])\n",
    "fig,ax = plt.subplots(3,3)\n",
    "ax[0,0].imshow(predU[2])\n",
    "ax[0,1].imshow(train_data_noisy[2])\n",
    "ax[0,2].imshow(train_data_clean[2])\n",
    "\n",
    "\n",
    "predUnodense = modelUNoDense.predict(train_data_noisy[:10])\n",
    "\n",
    "ax[1,0].imshow(predUnodense[2])\n",
    "ax[1,1].imshow(train_data_noisy[2])\n",
    "ax[1,2].imshow(train_data_clean[2])\n",
    "\n",
    "#%%\n",
    "\n",
    "pred = model.predict(train_data_noisy[:10])\n",
    "\n",
    "ax[2,0].imshow(pred[2])\n",
    "ax[2,1].imshow(train_data_noisy[2])\n",
    "ax[2,2].imshow(train_data_clean[2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O_CmKLxiiaNd"
   },
   "source": [
    "def build_encoder(encoded_dimension):\n",
    "    model = Sequential([\n",
    "\n",
    "    Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(encoded_dimension, activation='relu')\n",
    "    ])\n",
    "    return model\n",
    "def build_decoder():\n",
    "    model = Sequential([\n",
    "    Dense(2 * 2 * 256, activation='relu'),\n",
    "    Reshape((2, 2, 256)),\n",
    "\n",
    "    Conv2DTranspose(filters=256, kernel_size=3,strides=1, padding='same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=128, kernel_size=3,strides=2, padding='same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=64, kernel_size=3,strides=2, padding='same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=32, kernel_size=3,strides=2, padding='same'),\n",
    "    ReLU(),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=3, kernel_size=3,strides=2, padding='same'),\n",
    "    Activation('sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "class SimpleDAEpadd2(tf.keras.Model):\n",
    "    def __init__(self,encoded_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.encoder = build_encoder(encoded_dimension)\n",
    "        self.decoder = build_decoder()\n",
    "    def call(self,x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8mUm-QqnFKr",
    "outputId": "dfb61fe1-be02-4119-d5a9-7ac6c0b245cb"
   },
   "source": [
    "modelpadd2 = SimpleDAEpadd2(256*2*2)\n",
    "modelpadd2.compile(loss = 'mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "padd2_history = modelpadd2.fit(train_data_noisy,train_data_clean, batch_size=64,verbose=1, epochs=40, validation_split=0.15, callbacks=[callback])\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "GSXnhIa3nQ-e",
    "outputId": "b38b94e7-ff78-4508-de27-d8452808b9ff"
   },
   "source": [
    "pred2padd = modelpadd2.predict(train_data_noisy[:10])\n",
    "fig,ax = plt.subplots(1,3)\n",
    "i = np.random.choice([x for x in range(10)])\n",
    "ax[2].imshow(pred2padd[i])\n",
    "ax[1].imshow(train_data_noisy[i])\n",
    "ax[0].imshow(train_data_clean[i])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ilhb4blx3cM1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "outputId": "4b089443-1946-46ae-ad7e-e6132e483a79"
   },
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "fig,ax = plt.subplots(2,4,figsize = (20,10))\n",
    "for i in range(2):\n",
    "  for j in range(4):\n",
    "    ax[i,j].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax[i,j].set_xlabel('epoch')\n",
    "    ax[i,j].set_ylabel('loss') if i == 0 else ax[i,j].set_ylabel('accuracy')\n",
    "ax[0,0].plot([i for i in range(40)],np.array([UneNoDenset_history.history['loss'], UneNoDenset_history.history['val_loss']]).T)\n",
    "ax[0,0].set_title('U-net  with dense layer loss')\n",
    "ax[0,0].legend(['loss','validation_loss'])\n",
    "ax[0,1].plot([i for i in range(40)],np.array([Unet_history.history['loss'], Unet_history.history['val_loss']]).T)\n",
    "ax[0,1].set_title('U-net without dense layer loss')\n",
    "ax[0,1].legend(['loss','validation_loss'])\n",
    "ax[0,2].plot([i for i in range(40)],np.array([Simple_DEA_history.history['loss'], Simple_DEA_history.history['val_loss']]).T)\n",
    "ax[0,2].set_title('Simple Autoencoder  loss')\n",
    "ax[0,2].legend(['loss','validation_loss'])\n",
    "ax[0,3].plot([i for i in range(40)],np.array([padd2_history.history['loss'], padd2_history.history['val_loss']]).T)\n",
    "ax[0,3].set_title('Simple Autoencoder with double transposition loss')\n",
    "ax[0,3].legend(['loss','validation_loss'])\n",
    "ax[1,0].plot([i for i in range(40)],np.array([UneNoDenset_history.history['accuracy'], UneNoDenset_history.history['val_accuracy']]).T)\n",
    "ax[1,0].set_title('U-net  with dense layer accuracy')\n",
    "ax[1,0].legend(['loss','validation_loss'])\n",
    "ax[1,1].plot([i for i in range(40)],np.array([Unet_history.history['accuracy'], Unet_history.history['val_accuracy']]).T)\n",
    "ax[1,1].set_title('U-net  without dense layer accuracy')\n",
    "ax[1,1].legend(['loss','validation_loss'])\n",
    "ax[1,2].plot([i for i in range(40)],np.array([Simple_DEA_history.history['accuracy'], Simple_DEA_history.history['val_accuracy']]).T)\n",
    "ax[1,2].set_title('Simple Autoencoder accuracy')\n",
    "ax[1,2].legend(['loss','validation_loss'])\n",
    "ax[1,3].plot([i for i in range(40)],np.array([padd2_history.history['accuracy'], padd2_history.history['val_accuracy']]).T)\n",
    "ax[1,3].set_title('Simple Autoencoder with double transposition  accuracy')\n",
    "ax[1,3].legend(['loss','validation_loss'])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h2yEyADT0_Os"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}